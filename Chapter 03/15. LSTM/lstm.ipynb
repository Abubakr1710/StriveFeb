{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ISE</th>\n",
       "      <th>ISE.1</th>\n",
       "      <th>SP</th>\n",
       "      <th>DAX</th>\n",
       "      <th>FTSE</th>\n",
       "      <th>NIKKEI</th>\n",
       "      <th>BOVESPA</th>\n",
       "      <th>EU</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-Jan-09</td>\n",
       "      <td>0.035754</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>-0.004679</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031190</td>\n",
       "      <td>0.012698</td>\n",
       "      <td>0.028524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6-Jan-09</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.007787</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.008773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Jan-09</td>\n",
       "      <td>-0.028862</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.030469</td>\n",
       "      <td>-0.017833</td>\n",
       "      <td>-0.028735</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>-0.035899</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>-0.020015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8-Jan-09</td>\n",
       "      <td>-0.062208</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>-0.040061</td>\n",
       "      <td>0.028283</td>\n",
       "      <td>-0.005561</td>\n",
       "      <td>-0.019424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-Jan-09</td>\n",
       "      <td>0.009860</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.010989</td>\n",
       "      <td>-0.007802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       ISE     ISE.1        SP       DAX      FTSE    NIKKEI  \\\n",
       "0  5-Jan-09  0.035754  0.038376 -0.004679  0.002193  0.003894  0.000000   \n",
       "1  6-Jan-09  0.025426  0.031813  0.007787  0.008455  0.012866  0.004162   \n",
       "2  7-Jan-09 -0.028862 -0.026353 -0.030469 -0.017833 -0.028735  0.017293   \n",
       "3  8-Jan-09 -0.062208 -0.084716  0.003391 -0.011726 -0.000466 -0.040061   \n",
       "4  9-Jan-09  0.009860  0.009658 -0.021533 -0.019873 -0.012710 -0.004474   \n",
       "\n",
       "    BOVESPA        EU        EM  \n",
       "0  0.031190  0.012698  0.028524  \n",
       "1  0.018920  0.011341  0.008773  \n",
       "2 -0.035899 -0.017073 -0.020015  \n",
       "3  0.028283 -0.005561 -0.019424  \n",
       "4 -0.009764 -0.010989 -0.007802  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('data_akbilgic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(df.shape[0]*0.8)\n",
    "df_train = df[:train_size]\n",
    "df_test = df[train_size:]\n",
    "\n",
    "df_train = df_train.values\n",
    "df_test =df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives the number of samples (batch_size) of size (n_steps) to extract\n",
    "# from the time series, and outputs such a sample\n",
    "def next_stock_batch(batch_size, n_steps, feat, n_features):\n",
    "    t_min = 0\n",
    "    t_max = feat.shape[0]\n",
    "  \n",
    "    # The inputs will be formed by 8 sequences taken from\n",
    "    # 7 time series [ISE.1,SP,DAX,FTSE,NIKKEI,BOVESPA,EU]\n",
    "    x = np.zeros((batch_size,n_steps,n_features))\n",
    "    \n",
    "    # We want to predict the returns of the Istambul stock\n",
    "    # taken into consideration the previous n_steps days\n",
    "    y = np.zeros((batch_size,n_steps))\n",
    "\n",
    "    # We chose batch_size random points from time series x-axis\n",
    "\n",
    "    starting_points = np.random.randint(0,t_max-n_steps-1,size=batch_size)    \n",
    "    #print(starting_points)\n",
    "    #print(feat.shape)\n",
    "    \n",
    "    # We create the batches for x using all time series (8) between t and t+n_steps]\n",
    "    for i, sp in enumerate(starting_points):\n",
    "        x[i] = feat[sp: sp+n_steps]\n",
    "        y[i] = feat[sp+1:sp+n_steps+1, 1]    \n",
    "    # We create the batches for y using only one time series between t+1 and t+n_steps+1\n",
    "    \n",
    "    #Save on x and y the time series data sequence and the prediction sequence\n",
    "\n",
    "    return x,y\n",
    "\n",
    "# x,y =  next_stock_batch(batch_size=32,n_steps=10, feat=feat, n_features=9)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.__init__() takes 1 positional argument but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Abubakr\\Documents\\GitHub\\StriveFeb\\Chapter 03\\15. LSTM\\lstm.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/StriveFeb/Chapter%2003/15.%20LSTM/lstm.ipynb#ch0000005?line=20'>21</a>\u001b[0m         out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/StriveFeb/Chapter%2003/15.%20LSTM/lstm.ipynb#ch0000005?line=21'>22</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Abubakr/Documents/GitHub/StriveFeb/Chapter%2003/15.%20LSTM/lstm.ipynb#ch0000005?line=23'>24</a>\u001b[0m model \u001b[39m=\u001b[39m LSTM(\u001b[39m9\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.__init__() takes 1 positional argument but 6 were given"
     ]
    }
   ],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def ___init__(self, input_size, hidden_size, num_layers, batch_size, seq_len):\n",
    "        super(). __init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size =batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first =True)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.batch_size*self.hidden_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, self.batch_size*self.seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0=torch.zeros((self.num_layers, self.batch_size, self.hidden_size ))\n",
    "\n",
    "        lstm_out, h_n = self.lstm(x,h_0)\n",
    "        last_hidden = h_n[-1]\n",
    "\n",
    "        x = F.relu(last_hidden.flatten()) # added this line, you can activate also the last hidden layer, for better performance\n",
    "        x = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "model = LSTM(9, 5, 10, 32, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c783155fdf7cc6e25183d446515f6b6ba379df7b28dd698d21634d1b4d5e58fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
