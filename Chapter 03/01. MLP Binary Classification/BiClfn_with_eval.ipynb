{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26775fcb0b0>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "T.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden1, num_hidden2, num_hidden3):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, num_hidden1)\n",
    "        self.linear2 = nn.Linear(num_hidden1, num_hidden2)\n",
    "        self.linear3 = nn.Linear(num_hidden2, num_hidden3)\n",
    "        self.linear4 = nn.Linear(num_hidden3, 1)\n",
    "        self.tan = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer1 = self.linear1(x)\n",
    "        act1 = self.tan(layer1)\n",
    "        layer2 = self.linear2(act1)\n",
    "        act2 = self.tan(layer2)\n",
    "        layer3 = self.linear3(act2)\n",
    "        act3 = self.tan(layer3)\n",
    "        layer4 = self.linear4(act3)\n",
    "        out = self.sigmoid(layer4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', header=None)\n",
    "X = T.tensor(data.drop(2, axis=1).values, dtype=T.float)\n",
    "y = T.tensor(data[2].values, dtype=T.float).view(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "model = NeuralNetwork(X.shape[1], 10,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Accuracy: 0.5\n",
      "Epoch 1, Accuracy: 0.5\n",
      "Epoch 2, Accuracy: 0.75\n",
      "Epoch 3, Accuracy: 0.6000000238418579\n",
      "Epoch 4, Accuracy: 0.75\n",
      "Epoch 5, Accuracy: 0.949999988079071\n",
      "Epoch 6, Accuracy: 0.8999999761581421\n",
      "Epoch 7, Accuracy: 0.800000011920929\n",
      "Epoch 8, Accuracy: 0.75\n",
      "Epoch 9, Accuracy: 0.6499999761581421\n",
      "Epoch 10, Accuracy: 0.6499999761581421\n",
      "Epoch 11, Accuracy: 0.6499999761581421\n",
      "Epoch 12, Accuracy: 0.699999988079071\n",
      "Epoch 13, Accuracy: 0.800000011920929\n",
      "Epoch 14, Accuracy: 0.800000011920929\n",
      "Epoch 15, Accuracy: 0.8500000238418579\n",
      "Epoch 16, Accuracy: 0.8500000238418579\n",
      "Epoch 17, Accuracy: 0.8999999761581421\n",
      "Epoch 18, Accuracy: 0.8999999761581421\n",
      "Epoch 19, Accuracy: 0.8999999761581421\n",
      "Epoch 20, Accuracy: 0.8999999761581421\n",
      "Epoch 21, Accuracy: 0.8999999761581421\n",
      "Epoch 22, Accuracy: 0.8999999761581421\n",
      "Epoch 23, Accuracy: 0.8999999761581421\n",
      "Epoch 24, Accuracy: 0.8999999761581421\n",
      "Epoch 25, Accuracy: 0.8999999761581421\n",
      "Epoch 26, Accuracy: 0.8999999761581421\n",
      "Epoch 27, Accuracy: 0.8999999761581421\n",
      "Epoch 28, Accuracy: 0.8999999761581421\n",
      "Epoch 29, Accuracy: 0.8999999761581421\n",
      "Epoch 30, Accuracy: 0.8999999761581421\n",
      "Epoch 31, Accuracy: 0.8999999761581421\n",
      "Epoch 32, Accuracy: 0.8999999761581421\n",
      "Epoch 33, Accuracy: 0.8999999761581421\n",
      "Epoch 34, Accuracy: 0.8999999761581421\n",
      "Epoch 35, Accuracy: 0.8999999761581421\n",
      "Epoch 36, Accuracy: 0.8999999761581421\n",
      "Epoch 37, Accuracy: 0.8999999761581421\n",
      "Epoch 38, Accuracy: 0.8999999761581421\n",
      "Epoch 39, Accuracy: 0.8999999761581421\n",
      "Epoch 40, Accuracy: 0.8999999761581421\n",
      "Epoch 41, Accuracy: 0.8999999761581421\n",
      "Epoch 42, Accuracy: 0.8999999761581421\n",
      "Epoch 43, Accuracy: 0.8999999761581421\n",
      "Epoch 44, Accuracy: 0.8999999761581421\n",
      "Epoch 45, Accuracy: 0.8999999761581421\n",
      "Epoch 46, Accuracy: 0.8999999761581421\n",
      "Epoch 47, Accuracy: 0.8999999761581421\n",
      "Epoch 48, Accuracy: 0.8999999761581421\n",
      "Epoch 49, Accuracy: 0.8999999761581421\n",
      "Epoch 50, Accuracy: 0.8999999761581421\n",
      "Epoch 51, Accuracy: 0.8999999761581421\n",
      "Epoch 52, Accuracy: 0.8999999761581421\n",
      "Epoch 53, Accuracy: 0.8999999761581421\n",
      "Epoch 54, Accuracy: 0.8999999761581421\n",
      "Epoch 55, Accuracy: 0.8999999761581421\n",
      "Epoch 56, Accuracy: 0.8999999761581421\n",
      "Epoch 57, Accuracy: 0.8999999761581421\n",
      "Epoch 58, Accuracy: 0.8999999761581421\n",
      "Epoch 59, Accuracy: 0.8999999761581421\n",
      "Epoch 60, Accuracy: 0.8999999761581421\n",
      "Epoch 61, Accuracy: 0.8999999761581421\n",
      "Epoch 62, Accuracy: 0.8999999761581421\n",
      "Epoch 63, Accuracy: 0.8999999761581421\n",
      "Epoch 64, Accuracy: 0.8999999761581421\n",
      "Epoch 65, Accuracy: 0.8999999761581421\n",
      "Epoch 66, Accuracy: 0.8999999761581421\n",
      "Epoch 67, Accuracy: 0.8999999761581421\n",
      "Epoch 68, Accuracy: 0.8999999761581421\n",
      "Epoch 69, Accuracy: 0.8999999761581421\n",
      "Epoch 70, Accuracy: 0.8999999761581421\n",
      "Epoch 71, Accuracy: 0.8999999761581421\n",
      "Epoch 72, Accuracy: 0.8999999761581421\n",
      "Epoch 73, Accuracy: 0.8999999761581421\n",
      "Epoch 74, Accuracy: 0.8999999761581421\n",
      "Epoch 75, Accuracy: 0.8999999761581421\n",
      "Epoch 76, Accuracy: 0.8999999761581421\n",
      "Epoch 77, Accuracy: 0.8999999761581421\n",
      "Epoch 78, Accuracy: 0.8999999761581421\n",
      "Epoch 79, Accuracy: 0.8999999761581421\n",
      "Epoch 80, Accuracy: 0.8999999761581421\n",
      "Epoch 81, Accuracy: 0.8999999761581421\n",
      "Epoch 82, Accuracy: 0.8999999761581421\n",
      "Epoch 83, Accuracy: 0.8999999761581421\n",
      "Epoch 84, Accuracy: 0.8999999761581421\n",
      "Epoch 85, Accuracy: 0.8999999761581421\n",
      "Epoch 86, Accuracy: 0.8999999761581421\n",
      "Epoch 87, Accuracy: 0.8999999761581421\n",
      "Epoch 88, Accuracy: 0.8999999761581421\n",
      "Epoch 89, Accuracy: 0.8999999761581421\n",
      "Epoch 90, Accuracy: 0.8999999761581421\n",
      "Epoch 91, Accuracy: 0.8999999761581421\n",
      "Epoch 92, Accuracy: 0.8999999761581421\n",
      "Epoch 93, Accuracy: 0.8999999761581421\n",
      "Epoch 94, Accuracy: 0.8999999761581421\n",
      "Epoch 95, Accuracy: 0.8999999761581421\n",
      "Epoch 96, Accuracy: 0.8999999761581421\n",
      "Epoch 97, Accuracy: 0.8999999761581421\n",
      "Epoch 98, Accuracy: 0.8999999761581421\n",
      "Epoch 99, Accuracy: 0.8999999761581421\n",
      "Epoch 100, Accuracy: 0.8999999761581421\n",
      "Epoch 101, Accuracy: 0.8999999761581421\n",
      "Epoch 102, Accuracy: 0.8999999761581421\n",
      "Epoch 103, Accuracy: 0.8999999761581421\n",
      "Epoch 104, Accuracy: 0.8999999761581421\n",
      "Epoch 105, Accuracy: 0.8999999761581421\n",
      "Epoch 106, Accuracy: 0.8999999761581421\n",
      "Epoch 107, Accuracy: 0.8999999761581421\n",
      "Epoch 108, Accuracy: 0.8999999761581421\n",
      "Epoch 109, Accuracy: 0.8999999761581421\n",
      "Epoch 110, Accuracy: 0.8999999761581421\n",
      "Epoch 111, Accuracy: 0.8999999761581421\n",
      "Epoch 112, Accuracy: 0.8999999761581421\n",
      "Epoch 113, Accuracy: 0.8999999761581421\n",
      "Epoch 114, Accuracy: 0.8999999761581421\n",
      "Epoch 115, Accuracy: 0.8999999761581421\n",
      "Epoch 116, Accuracy: 0.8999999761581421\n",
      "Epoch 117, Accuracy: 0.8999999761581421\n",
      "Epoch 118, Accuracy: 0.8999999761581421\n",
      "Epoch 119, Accuracy: 0.8999999761581421\n",
      "Epoch 120, Accuracy: 0.8999999761581421\n",
      "Epoch 121, Accuracy: 0.8999999761581421\n",
      "Epoch 122, Accuracy: 0.8999999761581421\n",
      "Epoch 123, Accuracy: 0.8999999761581421\n",
      "Epoch 124, Accuracy: 0.8999999761581421\n",
      "Epoch 125, Accuracy: 0.8999999761581421\n",
      "Epoch 126, Accuracy: 0.8999999761581421\n",
      "Epoch 127, Accuracy: 0.8999999761581421\n",
      "Epoch 128, Accuracy: 0.8999999761581421\n",
      "Epoch 129, Accuracy: 0.8999999761581421\n",
      "Epoch 130, Accuracy: 0.8999999761581421\n",
      "Epoch 131, Accuracy: 0.8999999761581421\n",
      "Epoch 132, Accuracy: 0.8999999761581421\n",
      "Epoch 133, Accuracy: 0.8999999761581421\n",
      "Epoch 134, Accuracy: 0.8999999761581421\n",
      "Epoch 135, Accuracy: 0.8999999761581421\n",
      "Epoch 136, Accuracy: 0.8999999761581421\n",
      "Epoch 137, Accuracy: 0.8999999761581421\n",
      "Epoch 138, Accuracy: 0.8999999761581421\n",
      "Epoch 139, Accuracy: 0.8999999761581421\n",
      "Epoch 140, Accuracy: 0.8999999761581421\n",
      "Epoch 141, Accuracy: 0.8999999761581421\n",
      "Epoch 142, Accuracy: 0.8999999761581421\n",
      "Epoch 143, Accuracy: 0.8999999761581421\n",
      "Epoch 144, Accuracy: 0.8999999761581421\n",
      "Epoch 145, Accuracy: 0.8999999761581421\n",
      "Epoch 146, Accuracy: 0.8999999761581421\n",
      "Epoch 147, Accuracy: 0.8999999761581421\n",
      "Epoch 148, Accuracy: 0.8999999761581421\n",
      "Epoch 149, Accuracy: 0.8999999761581421\n",
      "Epoch 150, Accuracy: 0.8999999761581421\n",
      "Epoch 151, Accuracy: 0.8999999761581421\n",
      "Epoch 152, Accuracy: 0.8999999761581421\n",
      "Epoch 153, Accuracy: 0.8999999761581421\n",
      "Epoch 154, Accuracy: 0.8999999761581421\n",
      "Epoch 155, Accuracy: 0.8999999761581421\n",
      "Epoch 156, Accuracy: 0.8999999761581421\n",
      "Epoch 157, Accuracy: 0.8999999761581421\n",
      "Epoch 158, Accuracy: 0.8999999761581421\n",
      "Epoch 159, Accuracy: 0.8999999761581421\n",
      "Epoch 160, Accuracy: 0.8999999761581421\n",
      "Epoch 161, Accuracy: 0.8999999761581421\n",
      "Epoch 162, Accuracy: 0.8999999761581421\n",
      "Epoch 163, Accuracy: 0.8999999761581421\n",
      "Epoch 164, Accuracy: 0.8999999761581421\n",
      "Epoch 165, Accuracy: 0.8999999761581421\n",
      "Epoch 166, Accuracy: 0.8999999761581421\n",
      "Epoch 167, Accuracy: 0.8999999761581421\n",
      "Epoch 168, Accuracy: 0.8999999761581421\n",
      "Epoch 169, Accuracy: 0.8999999761581421\n",
      "Epoch 170, Accuracy: 0.8999999761581421\n",
      "Epoch 171, Accuracy: 0.8999999761581421\n",
      "Epoch 172, Accuracy: 0.8999999761581421\n",
      "Epoch 173, Accuracy: 0.8999999761581421\n",
      "Epoch 174, Accuracy: 0.8999999761581421\n",
      "Epoch 175, Accuracy: 0.8999999761581421\n",
      "Epoch 176, Accuracy: 0.8999999761581421\n",
      "Epoch 177, Accuracy: 0.8999999761581421\n",
      "Epoch 178, Accuracy: 0.8999999761581421\n",
      "Epoch 179, Accuracy: 0.8999999761581421\n",
      "Epoch 180, Accuracy: 0.8999999761581421\n",
      "Epoch 181, Accuracy: 0.8999999761581421\n",
      "Epoch 182, Accuracy: 0.8999999761581421\n",
      "Epoch 183, Accuracy: 0.8999999761581421\n",
      "Epoch 184, Accuracy: 0.8999999761581421\n",
      "Epoch 185, Accuracy: 0.8999999761581421\n",
      "Epoch 186, Accuracy: 0.8999999761581421\n",
      "Epoch 187, Accuracy: 0.8999999761581421\n",
      "Epoch 188, Accuracy: 0.8999999761581421\n",
      "Epoch 189, Accuracy: 0.8999999761581421\n",
      "Epoch 190, Accuracy: 0.8999999761581421\n",
      "Epoch 191, Accuracy: 0.8999999761581421\n",
      "Epoch 192, Accuracy: 0.8999999761581421\n",
      "Epoch 193, Accuracy: 0.8999999761581421\n",
      "Epoch 194, Accuracy: 0.8999999761581421\n",
      "Epoch 195, Accuracy: 0.8999999761581421\n",
      "Epoch 196, Accuracy: 0.8999999761581421\n",
      "Epoch 197, Accuracy: 0.8999999761581421\n",
      "Epoch 198, Accuracy: 0.8999999761581421\n",
      "Epoch 199, Accuracy: 0.8999999761581421\n",
      "Epoch 200, Accuracy: 0.8999999761581421\n",
      "Epoch 201, Accuracy: 0.8999999761581421\n",
      "Epoch 202, Accuracy: 0.8999999761581421\n",
      "Epoch 203, Accuracy: 0.8999999761581421\n",
      "Epoch 204, Accuracy: 0.8999999761581421\n",
      "Epoch 205, Accuracy: 0.8999999761581421\n",
      "Epoch 206, Accuracy: 0.8999999761581421\n",
      "Epoch 207, Accuracy: 0.8999999761581421\n",
      "Epoch 208, Accuracy: 0.8999999761581421\n",
      "Epoch 209, Accuracy: 0.8999999761581421\n",
      "Epoch 210, Accuracy: 0.8999999761581421\n",
      "Epoch 211, Accuracy: 0.8999999761581421\n",
      "Epoch 212, Accuracy: 0.8999999761581421\n",
      "Epoch 213, Accuracy: 0.8999999761581421\n",
      "Epoch 214, Accuracy: 0.8999999761581421\n",
      "Epoch 215, Accuracy: 0.8999999761581421\n",
      "Epoch 216, Accuracy: 0.8999999761581421\n",
      "Epoch 217, Accuracy: 0.8999999761581421\n",
      "Epoch 218, Accuracy: 0.8999999761581421\n",
      "Epoch 219, Accuracy: 0.8500000238418579\n",
      "Epoch 220, Accuracy: 0.8500000238418579\n",
      "Epoch 221, Accuracy: 0.8500000238418579\n",
      "Epoch 222, Accuracy: 0.8500000238418579\n",
      "Epoch 223, Accuracy: 0.8500000238418579\n",
      "Epoch 224, Accuracy: 0.8500000238418579\n",
      "Epoch 225, Accuracy: 0.8500000238418579\n",
      "Epoch 226, Accuracy: 0.8500000238418579\n",
      "Epoch 227, Accuracy: 0.8500000238418579\n",
      "Epoch 228, Accuracy: 0.8500000238418579\n",
      "Epoch 229, Accuracy: 0.8500000238418579\n",
      "Epoch 230, Accuracy: 0.8500000238418579\n",
      "Epoch 231, Accuracy: 0.8500000238418579\n",
      "Epoch 232, Accuracy: 0.8500000238418579\n",
      "Epoch 233, Accuracy: 0.8500000238418579\n",
      "Epoch 234, Accuracy: 0.8500000238418579\n",
      "Epoch 235, Accuracy: 0.8500000238418579\n",
      "Epoch 236, Accuracy: 0.8500000238418579\n",
      "Epoch 237, Accuracy: 0.8500000238418579\n",
      "Epoch 238, Accuracy: 0.8500000238418579\n",
      "Epoch 239, Accuracy: 0.8500000238418579\n",
      "Epoch 240, Accuracy: 0.8500000238418579\n",
      "Epoch 241, Accuracy: 0.8500000238418579\n",
      "Epoch 242, Accuracy: 0.8500000238418579\n",
      "Epoch 243, Accuracy: 0.8500000238418579\n",
      "Epoch 244, Accuracy: 0.8500000238418579\n",
      "Epoch 245, Accuracy: 0.8500000238418579\n",
      "Epoch 246, Accuracy: 0.8500000238418579\n",
      "Epoch 247, Accuracy: 0.8500000238418579\n",
      "Epoch 248, Accuracy: 0.8500000238418579\n",
      "Epoch 249, Accuracy: 0.8500000238418579\n",
      "Epoch 250, Accuracy: 0.8500000238418579\n",
      "Epoch 251, Accuracy: 0.8500000238418579\n",
      "Epoch 252, Accuracy: 0.8500000238418579\n",
      "Epoch 253, Accuracy: 0.8500000238418579\n",
      "Epoch 254, Accuracy: 0.8500000238418579\n",
      "Epoch 255, Accuracy: 0.8500000238418579\n",
      "Epoch 256, Accuracy: 0.8500000238418579\n",
      "Epoch 257, Accuracy: 0.8500000238418579\n",
      "Epoch 258, Accuracy: 0.8500000238418579\n",
      "Epoch 259, Accuracy: 0.8500000238418579\n",
      "Epoch 260, Accuracy: 0.8500000238418579\n",
      "Epoch 261, Accuracy: 0.8500000238418579\n",
      "Epoch 262, Accuracy: 0.8500000238418579\n",
      "Epoch 263, Accuracy: 0.8500000238418579\n",
      "Epoch 264, Accuracy: 0.8500000238418579\n",
      "Epoch 265, Accuracy: 0.8500000238418579\n",
      "Epoch 266, Accuracy: 0.8500000238418579\n",
      "Epoch 267, Accuracy: 0.8500000238418579\n",
      "Epoch 268, Accuracy: 0.8500000238418579\n",
      "Epoch 269, Accuracy: 0.8500000238418579\n",
      "Epoch 270, Accuracy: 0.8500000238418579\n",
      "Epoch 271, Accuracy: 0.8500000238418579\n",
      "Epoch 272, Accuracy: 0.8500000238418579\n",
      "Epoch 273, Accuracy: 0.8500000238418579\n",
      "Epoch 274, Accuracy: 0.8500000238418579\n",
      "Epoch 275, Accuracy: 0.8500000238418579\n",
      "Epoch 276, Accuracy: 0.8500000238418579\n",
      "Epoch 277, Accuracy: 0.8500000238418579\n",
      "Epoch 278, Accuracy: 0.8500000238418579\n",
      "Epoch 279, Accuracy: 0.8500000238418579\n",
      "Epoch 280, Accuracy: 0.8500000238418579\n",
      "Epoch 281, Accuracy: 0.8500000238418579\n",
      "Epoch 282, Accuracy: 0.8500000238418579\n",
      "Epoch 283, Accuracy: 0.8500000238418579\n",
      "Epoch 284, Accuracy: 0.8500000238418579\n",
      "Epoch 285, Accuracy: 0.8500000238418579\n",
      "Epoch 286, Accuracy: 0.8500000238418579\n",
      "Epoch 287, Accuracy: 0.8500000238418579\n",
      "Epoch 288, Accuracy: 0.8500000238418579\n",
      "Epoch 289, Accuracy: 0.8500000238418579\n",
      "Epoch 290, Accuracy: 0.8500000238418579\n",
      "Epoch 291, Accuracy: 0.8500000238418579\n",
      "Epoch 292, Accuracy: 0.8500000238418579\n",
      "Epoch 293, Accuracy: 0.8500000238418579\n",
      "Epoch 294, Accuracy: 0.8500000238418579\n",
      "Epoch 295, Accuracy: 0.8500000238418579\n",
      "Epoch 296, Accuracy: 0.8500000238418579\n",
      "Epoch 297, Accuracy: 0.8500000238418579\n",
      "Epoch 298, Accuracy: 0.8500000238418579\n",
      "Epoch 299, Accuracy: 0.8500000238418579\n",
      "Epoch 300, Accuracy: 0.8500000238418579\n",
      "Epoch 301, Accuracy: 0.8500000238418579\n",
      "Epoch 302, Accuracy: 0.8500000238418579\n",
      "Epoch 303, Accuracy: 0.8500000238418579\n",
      "Epoch 304, Accuracy: 0.8500000238418579\n",
      "Epoch 305, Accuracy: 0.8500000238418579\n",
      "Epoch 306, Accuracy: 0.8500000238418579\n",
      "Epoch 307, Accuracy: 0.8500000238418579\n",
      "Epoch 308, Accuracy: 0.8500000238418579\n",
      "Epoch 309, Accuracy: 0.8500000238418579\n",
      "Epoch 310, Accuracy: 0.8500000238418579\n",
      "Epoch 311, Accuracy: 0.8500000238418579\n",
      "Epoch 312, Accuracy: 0.8500000238418579\n",
      "Epoch 313, Accuracy: 0.8500000238418579\n",
      "Epoch 314, Accuracy: 0.8500000238418579\n",
      "Epoch 315, Accuracy: 0.8500000238418579\n",
      "Epoch 316, Accuracy: 0.8500000238418579\n",
      "Epoch 317, Accuracy: 0.8500000238418579\n",
      "Epoch 318, Accuracy: 0.8500000238418579\n",
      "Epoch 319, Accuracy: 0.8500000238418579\n",
      "Epoch 320, Accuracy: 0.8500000238418579\n",
      "Epoch 321, Accuracy: 0.8500000238418579\n",
      "Epoch 322, Accuracy: 0.8500000238418579\n",
      "Epoch 323, Accuracy: 0.8500000238418579\n",
      "Epoch 324, Accuracy: 0.8500000238418579\n",
      "Epoch 325, Accuracy: 0.8500000238418579\n",
      "Epoch 326, Accuracy: 0.8500000238418579\n",
      "Epoch 327, Accuracy: 0.8500000238418579\n",
      "Epoch 328, Accuracy: 0.8500000238418579\n",
      "Epoch 329, Accuracy: 0.8500000238418579\n",
      "Epoch 330, Accuracy: 0.8500000238418579\n",
      "Epoch 331, Accuracy: 0.8500000238418579\n",
      "Epoch 332, Accuracy: 0.8500000238418579\n",
      "Epoch 333, Accuracy: 0.8500000238418579\n",
      "Epoch 334, Accuracy: 0.8500000238418579\n",
      "Epoch 335, Accuracy: 0.8500000238418579\n",
      "Epoch 336, Accuracy: 0.8500000238418579\n",
      "Epoch 337, Accuracy: 0.8500000238418579\n",
      "Epoch 338, Accuracy: 0.8500000238418579\n",
      "Epoch 339, Accuracy: 0.8500000238418579\n",
      "Epoch 340, Accuracy: 0.8500000238418579\n",
      "Epoch 341, Accuracy: 0.8500000238418579\n",
      "Epoch 342, Accuracy: 0.8500000238418579\n",
      "Epoch 343, Accuracy: 0.8500000238418579\n",
      "Epoch 344, Accuracy: 0.8500000238418579\n",
      "Epoch 345, Accuracy: 0.8500000238418579\n",
      "Epoch 346, Accuracy: 0.8500000238418579\n",
      "Epoch 347, Accuracy: 0.8500000238418579\n",
      "Epoch 348, Accuracy: 0.8500000238418579\n",
      "Epoch 349, Accuracy: 0.8500000238418579\n",
      "Epoch 350, Accuracy: 0.8500000238418579\n",
      "Epoch 351, Accuracy: 0.8500000238418579\n",
      "Epoch 352, Accuracy: 0.8500000238418579\n",
      "Epoch 353, Accuracy: 0.8500000238418579\n",
      "Epoch 354, Accuracy: 0.8500000238418579\n",
      "Epoch 355, Accuracy: 0.8500000238418579\n",
      "Epoch 356, Accuracy: 0.8500000238418579\n",
      "Epoch 357, Accuracy: 0.8500000238418579\n",
      "Epoch 358, Accuracy: 0.8500000238418579\n",
      "Epoch 359, Accuracy: 0.8500000238418579\n",
      "Epoch 360, Accuracy: 0.8500000238418579\n",
      "Epoch 361, Accuracy: 0.8500000238418579\n",
      "Epoch 362, Accuracy: 0.8500000238418579\n",
      "Epoch 363, Accuracy: 0.8500000238418579\n",
      "Epoch 364, Accuracy: 0.8500000238418579\n",
      "Epoch 365, Accuracy: 0.8500000238418579\n",
      "Epoch 366, Accuracy: 0.8500000238418579\n",
      "Epoch 367, Accuracy: 0.8500000238418579\n",
      "Epoch 368, Accuracy: 0.8500000238418579\n",
      "Epoch 369, Accuracy: 0.8500000238418579\n",
      "Epoch 370, Accuracy: 0.8500000238418579\n",
      "Epoch 371, Accuracy: 0.8500000238418579\n",
      "Epoch 372, Accuracy: 0.8500000238418579\n",
      "Epoch 373, Accuracy: 0.8500000238418579\n",
      "Epoch 374, Accuracy: 0.8500000238418579\n",
      "Epoch 375, Accuracy: 0.8500000238418579\n",
      "Epoch 376, Accuracy: 0.8500000238418579\n",
      "Epoch 377, Accuracy: 0.8500000238418579\n",
      "Epoch 378, Accuracy: 0.8500000238418579\n",
      "Epoch 379, Accuracy: 0.8500000238418579\n",
      "Epoch 380, Accuracy: 0.8500000238418579\n",
      "Epoch 381, Accuracy: 0.8500000238418579\n",
      "Epoch 382, Accuracy: 0.8500000238418579\n",
      "Epoch 383, Accuracy: 0.8500000238418579\n",
      "Epoch 384, Accuracy: 0.8500000238418579\n",
      "Epoch 385, Accuracy: 0.8500000238418579\n",
      "Epoch 386, Accuracy: 0.8500000238418579\n",
      "Epoch 387, Accuracy: 0.8500000238418579\n",
      "Epoch 388, Accuracy: 0.8500000238418579\n",
      "Epoch 389, Accuracy: 0.8500000238418579\n",
      "Epoch 390, Accuracy: 0.8500000238418579\n",
      "Epoch 391, Accuracy: 0.8500000238418579\n",
      "Epoch 392, Accuracy: 0.8500000238418579\n",
      "Epoch 393, Accuracy: 0.8500000238418579\n",
      "Epoch 394, Accuracy: 0.8500000238418579\n",
      "Epoch 395, Accuracy: 0.8500000238418579\n",
      "Epoch 396, Accuracy: 0.8500000238418579\n",
      "Epoch 397, Accuracy: 0.8500000238418579\n",
      "Epoch 398, Accuracy: 0.8500000238418579\n",
      "Epoch 399, Accuracy: 0.8500000238418579\n",
      "Epoch 400, Accuracy: 0.8500000238418579\n",
      "Epoch 401, Accuracy: 0.8500000238418579\n",
      "Epoch 402, Accuracy: 0.8500000238418579\n",
      "Epoch 403, Accuracy: 0.8500000238418579\n",
      "Epoch 404, Accuracy: 0.8500000238418579\n",
      "Epoch 405, Accuracy: 0.8500000238418579\n",
      "Epoch 406, Accuracy: 0.8500000238418579\n",
      "Epoch 407, Accuracy: 0.8500000238418579\n",
      "Epoch 408, Accuracy: 0.8500000238418579\n",
      "Epoch 409, Accuracy: 0.8500000238418579\n",
      "Epoch 410, Accuracy: 0.8500000238418579\n",
      "Epoch 411, Accuracy: 0.8500000238418579\n",
      "Epoch 412, Accuracy: 0.8500000238418579\n",
      "Epoch 413, Accuracy: 0.8500000238418579\n",
      "Epoch 414, Accuracy: 0.8500000238418579\n",
      "Epoch 415, Accuracy: 0.8500000238418579\n",
      "Epoch 416, Accuracy: 0.8500000238418579\n",
      "Epoch 417, Accuracy: 0.8500000238418579\n",
      "Epoch 418, Accuracy: 0.8500000238418579\n",
      "Epoch 419, Accuracy: 0.8500000238418579\n",
      "Epoch 420, Accuracy: 0.8500000238418579\n",
      "Epoch 421, Accuracy: 0.8500000238418579\n",
      "Epoch 422, Accuracy: 0.8500000238418579\n",
      "Epoch 423, Accuracy: 0.8500000238418579\n",
      "Epoch 424, Accuracy: 0.8500000238418579\n",
      "Epoch 425, Accuracy: 0.8500000238418579\n",
      "Epoch 426, Accuracy: 0.8500000238418579\n",
      "Epoch 427, Accuracy: 0.8500000238418579\n",
      "Epoch 428, Accuracy: 0.8500000238418579\n",
      "Epoch 429, Accuracy: 0.8500000238418579\n",
      "Epoch 430, Accuracy: 0.8500000238418579\n",
      "Epoch 431, Accuracy: 0.8500000238418579\n",
      "Epoch 432, Accuracy: 0.8500000238418579\n",
      "Epoch 433, Accuracy: 0.8500000238418579\n",
      "Epoch 434, Accuracy: 0.8500000238418579\n",
      "Epoch 435, Accuracy: 0.8500000238418579\n",
      "Epoch 436, Accuracy: 0.8500000238418579\n",
      "Epoch 437, Accuracy: 0.8500000238418579\n",
      "Epoch 438, Accuracy: 0.8500000238418579\n",
      "Epoch 439, Accuracy: 0.8500000238418579\n",
      "Epoch 440, Accuracy: 0.8500000238418579\n",
      "Epoch 441, Accuracy: 0.8500000238418579\n",
      "Epoch 442, Accuracy: 0.8500000238418579\n",
      "Epoch 443, Accuracy: 0.8500000238418579\n",
      "Epoch 444, Accuracy: 0.8500000238418579\n",
      "Epoch 445, Accuracy: 0.8500000238418579\n",
      "Epoch 446, Accuracy: 0.8500000238418579\n",
      "Epoch 447, Accuracy: 0.8500000238418579\n",
      "Epoch 448, Accuracy: 0.8500000238418579\n",
      "Epoch 449, Accuracy: 0.8500000238418579\n",
      "Epoch 450, Accuracy: 0.8500000238418579\n",
      "Epoch 451, Accuracy: 0.8500000238418579\n",
      "Epoch 452, Accuracy: 0.8500000238418579\n",
      "Epoch 453, Accuracy: 0.8500000238418579\n",
      "Epoch 454, Accuracy: 0.8500000238418579\n",
      "Epoch 455, Accuracy: 0.8500000238418579\n",
      "Epoch 456, Accuracy: 0.8500000238418579\n",
      "Epoch 457, Accuracy: 0.8500000238418579\n",
      "Epoch 458, Accuracy: 0.8500000238418579\n",
      "Epoch 459, Accuracy: 0.8500000238418579\n",
      "Epoch 460, Accuracy: 0.8500000238418579\n",
      "Epoch 461, Accuracy: 0.8500000238418579\n",
      "Epoch 462, Accuracy: 0.8500000238418579\n",
      "Epoch 463, Accuracy: 0.8500000238418579\n",
      "Epoch 464, Accuracy: 0.8500000238418579\n",
      "Epoch 465, Accuracy: 0.8500000238418579\n",
      "Epoch 466, Accuracy: 0.8500000238418579\n",
      "Epoch 467, Accuracy: 0.8500000238418579\n",
      "Epoch 468, Accuracy: 0.8500000238418579\n",
      "Epoch 469, Accuracy: 0.8500000238418579\n",
      "Epoch 470, Accuracy: 0.8500000238418579\n",
      "Epoch 471, Accuracy: 0.8500000238418579\n",
      "Epoch 472, Accuracy: 0.8500000238418579\n",
      "Epoch 473, Accuracy: 0.8500000238418579\n",
      "Epoch 474, Accuracy: 0.8500000238418579\n",
      "Epoch 475, Accuracy: 0.8500000238418579\n",
      "Epoch 476, Accuracy: 0.8500000238418579\n",
      "Epoch 477, Accuracy: 0.8500000238418579\n",
      "Epoch 478, Accuracy: 0.8500000238418579\n",
      "Epoch 479, Accuracy: 0.8500000238418579\n",
      "Epoch 480, Accuracy: 0.8500000238418579\n",
      "Epoch 481, Accuracy: 0.8500000238418579\n",
      "Epoch 482, Accuracy: 0.8500000238418579\n",
      "Epoch 483, Accuracy: 0.8500000238418579\n",
      "Epoch 484, Accuracy: 0.8500000238418579\n",
      "Epoch 485, Accuracy: 0.8500000238418579\n",
      "Epoch 486, Accuracy: 0.8500000238418579\n",
      "Epoch 487, Accuracy: 0.8500000238418579\n",
      "Epoch 488, Accuracy: 0.8500000238418579\n",
      "Epoch 489, Accuracy: 0.8500000238418579\n",
      "Epoch 490, Accuracy: 0.8500000238418579\n",
      "Epoch 491, Accuracy: 0.8500000238418579\n",
      "Epoch 492, Accuracy: 0.8500000238418579\n",
      "Epoch 493, Accuracy: 0.8500000238418579\n",
      "Epoch 494, Accuracy: 0.8500000238418579\n",
      "Epoch 495, Accuracy: 0.8500000238418579\n",
      "Epoch 496, Accuracy: 0.8500000238418579\n",
      "Epoch 497, Accuracy: 0.8500000238418579\n",
      "Epoch 498, Accuracy: 0.8500000238418579\n",
      "Epoch 499, Accuracy: 0.8500000238418579\n",
      "Epoch 500, Accuracy: 0.8500000238418579\n",
      "Epoch 501, Accuracy: 0.8500000238418579\n",
      "Epoch 502, Accuracy: 0.8500000238418579\n",
      "Epoch 503, Accuracy: 0.8500000238418579\n",
      "Epoch 504, Accuracy: 0.8500000238418579\n",
      "Epoch 505, Accuracy: 0.8500000238418579\n",
      "Epoch 506, Accuracy: 0.8500000238418579\n",
      "Epoch 507, Accuracy: 0.8500000238418579\n",
      "Epoch 508, Accuracy: 0.8500000238418579\n",
      "Epoch 509, Accuracy: 0.8500000238418579\n",
      "Epoch 510, Accuracy: 0.8500000238418579\n",
      "Epoch 511, Accuracy: 0.8500000238418579\n",
      "Epoch 512, Accuracy: 0.8500000238418579\n",
      "Epoch 513, Accuracy: 0.8500000238418579\n",
      "Epoch 514, Accuracy: 0.8500000238418579\n",
      "Epoch 515, Accuracy: 0.8500000238418579\n",
      "Epoch 516, Accuracy: 0.8500000238418579\n",
      "Epoch 517, Accuracy: 0.8500000238418579\n",
      "Epoch 518, Accuracy: 0.8500000238418579\n",
      "Epoch 519, Accuracy: 0.8500000238418579\n",
      "Epoch 520, Accuracy: 0.8500000238418579\n",
      "Epoch 521, Accuracy: 0.8500000238418579\n",
      "Epoch 522, Accuracy: 0.8500000238418579\n",
      "Epoch 523, Accuracy: 0.8500000238418579\n",
      "Epoch 524, Accuracy: 0.8500000238418579\n",
      "Epoch 525, Accuracy: 0.8500000238418579\n",
      "Epoch 526, Accuracy: 0.8500000238418579\n",
      "Epoch 527, Accuracy: 0.8500000238418579\n",
      "Epoch 528, Accuracy: 0.8500000238418579\n",
      "Epoch 529, Accuracy: 0.8500000238418579\n",
      "Epoch 530, Accuracy: 0.8500000238418579\n",
      "Epoch 531, Accuracy: 0.8500000238418579\n",
      "Epoch 532, Accuracy: 0.8500000238418579\n",
      "Epoch 533, Accuracy: 0.8500000238418579\n",
      "Epoch 534, Accuracy: 0.8500000238418579\n",
      "Epoch 535, Accuracy: 0.8500000238418579\n",
      "Epoch 536, Accuracy: 0.8500000238418579\n",
      "Epoch 537, Accuracy: 0.8500000238418579\n",
      "Epoch 538, Accuracy: 0.8500000238418579\n",
      "Epoch 539, Accuracy: 0.8500000238418579\n",
      "Epoch 540, Accuracy: 0.8500000238418579\n",
      "Epoch 541, Accuracy: 0.8500000238418579\n",
      "Epoch 542, Accuracy: 0.8500000238418579\n",
      "Epoch 543, Accuracy: 0.8500000238418579\n",
      "Epoch 544, Accuracy: 0.8500000238418579\n",
      "Epoch 545, Accuracy: 0.8500000238418579\n",
      "Epoch 546, Accuracy: 0.8500000238418579\n",
      "Epoch 547, Accuracy: 0.8500000238418579\n",
      "Epoch 548, Accuracy: 0.8500000238418579\n",
      "Epoch 549, Accuracy: 0.8500000238418579\n",
      "Epoch 550, Accuracy: 0.8500000238418579\n",
      "Epoch 551, Accuracy: 0.8500000238418579\n",
      "Epoch 552, Accuracy: 0.8500000238418579\n",
      "Epoch 553, Accuracy: 0.8500000238418579\n",
      "Epoch 554, Accuracy: 0.8500000238418579\n",
      "Epoch 555, Accuracy: 0.8500000238418579\n",
      "Epoch 556, Accuracy: 0.8500000238418579\n",
      "Epoch 557, Accuracy: 0.8500000238418579\n",
      "Epoch 558, Accuracy: 0.8500000238418579\n",
      "Epoch 559, Accuracy: 0.8500000238418579\n",
      "Epoch 560, Accuracy: 0.8500000238418579\n",
      "Epoch 561, Accuracy: 0.8500000238418579\n",
      "Epoch 562, Accuracy: 0.8500000238418579\n",
      "Epoch 563, Accuracy: 0.8500000238418579\n",
      "Epoch 564, Accuracy: 0.8500000238418579\n",
      "Epoch 565, Accuracy: 0.8500000238418579\n",
      "Epoch 566, Accuracy: 0.8500000238418579\n",
      "Epoch 567, Accuracy: 0.8500000238418579\n",
      "Epoch 568, Accuracy: 0.8500000238418579\n",
      "Epoch 569, Accuracy: 0.8500000238418579\n",
      "Epoch 570, Accuracy: 0.8500000238418579\n",
      "Epoch 571, Accuracy: 0.8500000238418579\n",
      "Epoch 572, Accuracy: 0.8500000238418579\n",
      "Epoch 573, Accuracy: 0.8500000238418579\n",
      "Epoch 574, Accuracy: 0.8500000238418579\n",
      "Epoch 575, Accuracy: 0.8500000238418579\n",
      "Epoch 576, Accuracy: 0.8500000238418579\n",
      "Epoch 577, Accuracy: 0.8500000238418579\n",
      "Epoch 578, Accuracy: 0.8500000238418579\n",
      "Epoch 579, Accuracy: 0.8500000238418579\n",
      "Epoch 580, Accuracy: 0.8500000238418579\n",
      "Epoch 581, Accuracy: 0.8500000238418579\n",
      "Epoch 582, Accuracy: 0.8500000238418579\n",
      "Epoch 583, Accuracy: 0.8500000238418579\n",
      "Epoch 584, Accuracy: 0.8500000238418579\n",
      "Epoch 585, Accuracy: 0.8500000238418579\n",
      "Epoch 586, Accuracy: 0.8500000238418579\n",
      "Epoch 587, Accuracy: 0.8500000238418579\n",
      "Epoch 588, Accuracy: 0.8500000238418579\n",
      "Epoch 589, Accuracy: 0.8500000238418579\n",
      "Epoch 590, Accuracy: 0.8500000238418579\n",
      "Epoch 591, Accuracy: 0.8500000238418579\n",
      "Epoch 592, Accuracy: 0.8500000238418579\n",
      "Epoch 593, Accuracy: 0.8500000238418579\n",
      "Epoch 594, Accuracy: 0.8500000238418579\n",
      "Epoch 595, Accuracy: 0.8500000238418579\n",
      "Epoch 596, Accuracy: 0.8500000238418579\n",
      "Epoch 597, Accuracy: 0.8500000238418579\n",
      "Epoch 598, Accuracy: 0.8500000238418579\n",
      "Epoch 599, Accuracy: 0.8500000238418579\n",
      "Epoch 600, Accuracy: 0.8500000238418579\n",
      "Epoch 601, Accuracy: 0.8500000238418579\n",
      "Epoch 602, Accuracy: 0.8500000238418579\n",
      "Epoch 603, Accuracy: 0.8500000238418579\n",
      "Epoch 604, Accuracy: 0.8500000238418579\n",
      "Epoch 605, Accuracy: 0.8500000238418579\n",
      "Epoch 606, Accuracy: 0.8500000238418579\n",
      "Epoch 607, Accuracy: 0.8500000238418579\n",
      "Epoch 608, Accuracy: 0.8500000238418579\n",
      "Epoch 609, Accuracy: 0.8500000238418579\n",
      "Epoch 610, Accuracy: 0.8500000238418579\n",
      "Epoch 611, Accuracy: 0.8500000238418579\n",
      "Epoch 612, Accuracy: 0.8500000238418579\n",
      "Epoch 613, Accuracy: 0.8500000238418579\n",
      "Epoch 614, Accuracy: 0.8500000238418579\n",
      "Epoch 615, Accuracy: 0.8500000238418579\n",
      "Epoch 616, Accuracy: 0.8500000238418579\n",
      "Epoch 617, Accuracy: 0.8500000238418579\n",
      "Epoch 618, Accuracy: 0.8500000238418579\n",
      "Epoch 619, Accuracy: 0.8500000238418579\n",
      "Epoch 620, Accuracy: 0.8500000238418579\n",
      "Epoch 621, Accuracy: 0.8500000238418579\n",
      "Epoch 622, Accuracy: 0.8500000238418579\n",
      "Epoch 623, Accuracy: 0.8500000238418579\n",
      "Epoch 624, Accuracy: 0.8500000238418579\n",
      "Epoch 625, Accuracy: 0.8500000238418579\n",
      "Epoch 626, Accuracy: 0.8500000238418579\n",
      "Epoch 627, Accuracy: 0.8500000238418579\n",
      "Epoch 628, Accuracy: 0.8500000238418579\n",
      "Epoch 629, Accuracy: 0.8500000238418579\n",
      "Epoch 630, Accuracy: 0.8500000238418579\n",
      "Epoch 631, Accuracy: 0.8500000238418579\n",
      "Epoch 632, Accuracy: 0.8500000238418579\n",
      "Epoch 633, Accuracy: 0.8500000238418579\n",
      "Epoch 634, Accuracy: 0.8500000238418579\n",
      "Epoch 635, Accuracy: 0.8500000238418579\n",
      "Epoch 636, Accuracy: 0.8500000238418579\n",
      "Epoch 637, Accuracy: 0.8500000238418579\n",
      "Epoch 638, Accuracy: 0.8500000238418579\n",
      "Epoch 639, Accuracy: 0.8500000238418579\n",
      "Epoch 640, Accuracy: 0.8500000238418579\n",
      "Epoch 641, Accuracy: 0.8500000238418579\n",
      "Epoch 642, Accuracy: 0.8500000238418579\n",
      "Epoch 643, Accuracy: 0.8500000238418579\n",
      "Epoch 644, Accuracy: 0.8500000238418579\n",
      "Epoch 645, Accuracy: 0.8500000238418579\n",
      "Epoch 646, Accuracy: 0.8500000238418579\n",
      "Epoch 647, Accuracy: 0.8500000238418579\n",
      "Epoch 648, Accuracy: 0.8500000238418579\n",
      "Epoch 649, Accuracy: 0.8500000238418579\n",
      "Epoch 650, Accuracy: 0.8500000238418579\n",
      "Epoch 651, Accuracy: 0.8500000238418579\n",
      "Epoch 652, Accuracy: 0.8500000238418579\n",
      "Epoch 653, Accuracy: 0.8500000238418579\n",
      "Epoch 654, Accuracy: 0.8500000238418579\n",
      "Epoch 655, Accuracy: 0.8500000238418579\n",
      "Epoch 656, Accuracy: 0.8500000238418579\n",
      "Epoch 657, Accuracy: 0.8500000238418579\n",
      "Epoch 658, Accuracy: 0.8500000238418579\n",
      "Epoch 659, Accuracy: 0.8500000238418579\n",
      "Epoch 660, Accuracy: 0.8500000238418579\n",
      "Epoch 661, Accuracy: 0.8500000238418579\n",
      "Epoch 662, Accuracy: 0.8500000238418579\n",
      "Epoch 663, Accuracy: 0.8500000238418579\n",
      "Epoch 664, Accuracy: 0.8500000238418579\n",
      "Epoch 665, Accuracy: 0.8500000238418579\n",
      "Epoch 666, Accuracy: 0.8500000238418579\n",
      "Epoch 667, Accuracy: 0.8500000238418579\n",
      "Epoch 668, Accuracy: 0.8500000238418579\n",
      "Epoch 669, Accuracy: 0.8500000238418579\n",
      "Epoch 670, Accuracy: 0.8500000238418579\n",
      "Epoch 671, Accuracy: 0.8500000238418579\n",
      "Epoch 672, Accuracy: 0.8500000238418579\n",
      "Epoch 673, Accuracy: 0.8500000238418579\n",
      "Epoch 674, Accuracy: 0.8500000238418579\n",
      "Epoch 675, Accuracy: 0.8500000238418579\n",
      "Epoch 676, Accuracy: 0.8500000238418579\n",
      "Epoch 677, Accuracy: 0.8500000238418579\n",
      "Epoch 678, Accuracy: 0.8500000238418579\n",
      "Epoch 679, Accuracy: 0.8500000238418579\n",
      "Epoch 680, Accuracy: 0.8500000238418579\n",
      "Epoch 681, Accuracy: 0.8500000238418579\n",
      "Epoch 682, Accuracy: 0.8500000238418579\n",
      "Epoch 683, Accuracy: 0.8500000238418579\n",
      "Epoch 684, Accuracy: 0.8500000238418579\n",
      "Epoch 685, Accuracy: 0.8500000238418579\n",
      "Epoch 686, Accuracy: 0.8500000238418579\n",
      "Epoch 687, Accuracy: 0.8500000238418579\n",
      "Epoch 688, Accuracy: 0.8500000238418579\n",
      "Epoch 689, Accuracy: 0.8500000238418579\n",
      "Epoch 690, Accuracy: 0.8500000238418579\n",
      "Epoch 691, Accuracy: 0.8500000238418579\n",
      "Epoch 692, Accuracy: 0.8500000238418579\n",
      "Epoch 693, Accuracy: 0.8500000238418579\n",
      "Epoch 694, Accuracy: 0.8500000238418579\n",
      "Epoch 695, Accuracy: 0.8500000238418579\n",
      "Epoch 696, Accuracy: 0.8500000238418579\n",
      "Epoch 697, Accuracy: 0.8500000238418579\n",
      "Epoch 698, Accuracy: 0.8500000238418579\n",
      "Epoch 699, Accuracy: 0.8500000238418579\n",
      "Epoch 700, Accuracy: 0.8500000238418579\n",
      "Epoch 701, Accuracy: 0.8500000238418579\n",
      "Epoch 702, Accuracy: 0.8500000238418579\n",
      "Epoch 703, Accuracy: 0.8500000238418579\n",
      "Epoch 704, Accuracy: 0.8500000238418579\n",
      "Epoch 705, Accuracy: 0.8500000238418579\n",
      "Epoch 706, Accuracy: 0.8500000238418579\n",
      "Epoch 707, Accuracy: 0.8500000238418579\n",
      "Epoch 708, Accuracy: 0.8500000238418579\n",
      "Epoch 709, Accuracy: 0.8500000238418579\n",
      "Epoch 710, Accuracy: 0.8500000238418579\n",
      "Epoch 711, Accuracy: 0.8500000238418579\n",
      "Epoch 712, Accuracy: 0.8500000238418579\n",
      "Epoch 713, Accuracy: 0.8500000238418579\n",
      "Epoch 714, Accuracy: 0.8500000238418579\n",
      "Epoch 715, Accuracy: 0.8500000238418579\n",
      "Epoch 716, Accuracy: 0.8500000238418579\n",
      "Epoch 717, Accuracy: 0.8500000238418579\n",
      "Epoch 718, Accuracy: 0.8500000238418579\n",
      "Epoch 719, Accuracy: 0.8500000238418579\n",
      "Epoch 720, Accuracy: 0.8500000238418579\n",
      "Epoch 721, Accuracy: 0.8500000238418579\n",
      "Epoch 722, Accuracy: 0.8500000238418579\n",
      "Epoch 723, Accuracy: 0.8500000238418579\n",
      "Epoch 724, Accuracy: 0.8500000238418579\n",
      "Epoch 725, Accuracy: 0.8500000238418579\n",
      "Epoch 726, Accuracy: 0.8500000238418579\n",
      "Epoch 727, Accuracy: 0.8500000238418579\n",
      "Epoch 728, Accuracy: 0.8500000238418579\n",
      "Epoch 729, Accuracy: 0.8500000238418579\n",
      "Epoch 730, Accuracy: 0.8500000238418579\n",
      "Epoch 731, Accuracy: 0.8500000238418579\n",
      "Epoch 732, Accuracy: 0.8500000238418579\n",
      "Epoch 733, Accuracy: 0.8500000238418579\n",
      "Epoch 734, Accuracy: 0.8500000238418579\n",
      "Epoch 735, Accuracy: 0.8500000238418579\n",
      "Epoch 736, Accuracy: 0.8500000238418579\n",
      "Epoch 737, Accuracy: 0.8500000238418579\n",
      "Epoch 738, Accuracy: 0.8500000238418579\n",
      "Epoch 739, Accuracy: 0.8500000238418579\n",
      "Epoch 740, Accuracy: 0.8500000238418579\n",
      "Epoch 741, Accuracy: 0.8500000238418579\n",
      "Epoch 742, Accuracy: 0.8500000238418579\n",
      "Epoch 743, Accuracy: 0.8500000238418579\n",
      "Epoch 744, Accuracy: 0.8500000238418579\n",
      "Epoch 745, Accuracy: 0.8500000238418579\n",
      "Epoch 746, Accuracy: 0.8500000238418579\n",
      "Epoch 747, Accuracy: 0.8500000238418579\n",
      "Epoch 748, Accuracy: 0.8500000238418579\n",
      "Epoch 749, Accuracy: 0.8500000238418579\n",
      "Epoch 750, Accuracy: 0.8500000238418579\n",
      "Epoch 751, Accuracy: 0.8500000238418579\n",
      "Epoch 752, Accuracy: 0.8500000238418579\n",
      "Epoch 753, Accuracy: 0.8500000238418579\n",
      "Epoch 754, Accuracy: 0.8500000238418579\n",
      "Epoch 755, Accuracy: 0.8500000238418579\n",
      "Epoch 756, Accuracy: 0.8500000238418579\n",
      "Epoch 757, Accuracy: 0.8500000238418579\n",
      "Epoch 758, Accuracy: 0.8500000238418579\n",
      "Epoch 759, Accuracy: 0.8500000238418579\n",
      "Epoch 760, Accuracy: 0.8500000238418579\n",
      "Epoch 761, Accuracy: 0.8500000238418579\n",
      "Epoch 762, Accuracy: 0.8500000238418579\n",
      "Epoch 763, Accuracy: 0.8500000238418579\n",
      "Epoch 764, Accuracy: 0.8500000238418579\n",
      "Epoch 765, Accuracy: 0.8500000238418579\n",
      "Epoch 766, Accuracy: 0.8500000238418579\n",
      "Epoch 767, Accuracy: 0.8500000238418579\n",
      "Epoch 768, Accuracy: 0.8500000238418579\n",
      "Epoch 769, Accuracy: 0.8500000238418579\n",
      "Epoch 770, Accuracy: 0.8500000238418579\n",
      "Epoch 771, Accuracy: 0.8500000238418579\n",
      "Epoch 772, Accuracy: 0.8500000238418579\n",
      "Epoch 773, Accuracy: 0.8500000238418579\n",
      "Epoch 774, Accuracy: 0.8500000238418579\n",
      "Epoch 775, Accuracy: 0.8500000238418579\n",
      "Epoch 776, Accuracy: 0.8500000238418579\n",
      "Epoch 777, Accuracy: 0.8500000238418579\n",
      "Epoch 778, Accuracy: 0.8500000238418579\n",
      "Epoch 779, Accuracy: 0.8500000238418579\n",
      "Epoch 780, Accuracy: 0.8500000238418579\n",
      "Epoch 781, Accuracy: 0.8500000238418579\n",
      "Epoch 782, Accuracy: 0.8500000238418579\n",
      "Epoch 783, Accuracy: 0.8500000238418579\n",
      "Epoch 784, Accuracy: 0.8500000238418579\n",
      "Epoch 785, Accuracy: 0.8500000238418579\n",
      "Epoch 786, Accuracy: 0.8500000238418579\n",
      "Epoch 787, Accuracy: 0.8500000238418579\n",
      "Epoch 788, Accuracy: 0.8500000238418579\n",
      "Epoch 789, Accuracy: 0.8500000238418579\n",
      "Epoch 790, Accuracy: 0.8500000238418579\n",
      "Epoch 791, Accuracy: 0.8500000238418579\n",
      "Epoch 792, Accuracy: 0.8500000238418579\n",
      "Epoch 793, Accuracy: 0.8500000238418579\n",
      "Epoch 794, Accuracy: 0.8500000238418579\n",
      "Epoch 795, Accuracy: 0.8500000238418579\n",
      "Epoch 796, Accuracy: 0.8500000238418579\n",
      "Epoch 797, Accuracy: 0.8500000238418579\n",
      "Epoch 798, Accuracy: 0.8500000238418579\n",
      "Epoch 799, Accuracy: 0.8500000238418579\n",
      "Epoch 800, Accuracy: 0.8500000238418579\n",
      "Epoch 801, Accuracy: 0.8500000238418579\n",
      "Epoch 802, Accuracy: 0.8500000238418579\n",
      "Epoch 803, Accuracy: 0.8500000238418579\n",
      "Epoch 804, Accuracy: 0.8500000238418579\n",
      "Epoch 805, Accuracy: 0.8500000238418579\n",
      "Epoch 806, Accuracy: 0.8500000238418579\n",
      "Epoch 807, Accuracy: 0.8500000238418579\n",
      "Epoch 808, Accuracy: 0.8500000238418579\n",
      "Epoch 809, Accuracy: 0.8500000238418579\n",
      "Epoch 810, Accuracy: 0.8500000238418579\n",
      "Epoch 811, Accuracy: 0.8500000238418579\n",
      "Epoch 812, Accuracy: 0.8500000238418579\n",
      "Epoch 813, Accuracy: 0.8500000238418579\n",
      "Epoch 814, Accuracy: 0.8500000238418579\n",
      "Epoch 815, Accuracy: 0.8500000238418579\n",
      "Epoch 816, Accuracy: 0.8500000238418579\n",
      "Epoch 817, Accuracy: 0.8500000238418579\n",
      "Epoch 818, Accuracy: 0.8500000238418579\n",
      "Epoch 819, Accuracy: 0.8500000238418579\n",
      "Epoch 820, Accuracy: 0.8500000238418579\n",
      "Epoch 821, Accuracy: 0.8500000238418579\n",
      "Epoch 822, Accuracy: 0.8500000238418579\n",
      "Epoch 823, Accuracy: 0.8500000238418579\n",
      "Epoch 824, Accuracy: 0.8500000238418579\n",
      "Epoch 825, Accuracy: 0.8500000238418579\n",
      "Epoch 826, Accuracy: 0.8500000238418579\n",
      "Epoch 827, Accuracy: 0.8500000238418579\n",
      "Epoch 828, Accuracy: 0.8500000238418579\n",
      "Epoch 829, Accuracy: 0.8500000238418579\n",
      "Epoch 830, Accuracy: 0.8500000238418579\n",
      "Epoch 831, Accuracy: 0.8500000238418579\n",
      "Epoch 832, Accuracy: 0.8500000238418579\n",
      "Epoch 833, Accuracy: 0.8500000238418579\n",
      "Epoch 834, Accuracy: 0.8500000238418579\n",
      "Epoch 835, Accuracy: 0.8500000238418579\n",
      "Epoch 836, Accuracy: 0.8500000238418579\n",
      "Epoch 837, Accuracy: 0.8500000238418579\n",
      "Epoch 838, Accuracy: 0.8500000238418579\n",
      "Epoch 839, Accuracy: 0.8500000238418579\n",
      "Epoch 840, Accuracy: 0.8500000238418579\n",
      "Epoch 841, Accuracy: 0.8500000238418579\n",
      "Epoch 842, Accuracy: 0.8500000238418579\n",
      "Epoch 843, Accuracy: 0.8500000238418579\n",
      "Epoch 844, Accuracy: 0.8500000238418579\n",
      "Epoch 845, Accuracy: 0.8500000238418579\n",
      "Epoch 846, Accuracy: 0.8500000238418579\n",
      "Epoch 847, Accuracy: 0.8500000238418579\n",
      "Epoch 848, Accuracy: 0.8500000238418579\n",
      "Epoch 849, Accuracy: 0.8500000238418579\n",
      "Epoch 850, Accuracy: 0.8500000238418579\n",
      "Epoch 851, Accuracy: 0.8500000238418579\n",
      "Epoch 852, Accuracy: 0.8500000238418579\n",
      "Epoch 853, Accuracy: 0.8500000238418579\n",
      "Epoch 854, Accuracy: 0.8500000238418579\n",
      "Epoch 855, Accuracy: 0.8500000238418579\n",
      "Epoch 856, Accuracy: 0.8500000238418579\n",
      "Epoch 857, Accuracy: 0.8500000238418579\n",
      "Epoch 858, Accuracy: 0.8500000238418579\n",
      "Epoch 859, Accuracy: 0.8500000238418579\n",
      "Epoch 860, Accuracy: 0.8500000238418579\n",
      "Epoch 861, Accuracy: 0.8500000238418579\n",
      "Epoch 862, Accuracy: 0.8500000238418579\n",
      "Epoch 863, Accuracy: 0.8500000238418579\n",
      "Epoch 864, Accuracy: 0.8500000238418579\n",
      "Epoch 865, Accuracy: 0.8500000238418579\n",
      "Epoch 866, Accuracy: 0.8500000238418579\n",
      "Epoch 867, Accuracy: 0.8500000238418579\n",
      "Epoch 868, Accuracy: 0.8500000238418579\n",
      "Epoch 869, Accuracy: 0.8500000238418579\n",
      "Epoch 870, Accuracy: 0.8500000238418579\n",
      "Epoch 871, Accuracy: 0.8500000238418579\n",
      "Epoch 872, Accuracy: 0.8500000238418579\n",
      "Epoch 873, Accuracy: 0.8500000238418579\n",
      "Epoch 874, Accuracy: 0.8500000238418579\n",
      "Epoch 875, Accuracy: 0.8500000238418579\n",
      "Epoch 876, Accuracy: 0.8500000238418579\n",
      "Epoch 877, Accuracy: 0.8500000238418579\n",
      "Epoch 878, Accuracy: 0.8500000238418579\n",
      "Epoch 879, Accuracy: 0.8500000238418579\n",
      "Epoch 880, Accuracy: 0.8500000238418579\n",
      "Epoch 881, Accuracy: 0.8500000238418579\n",
      "Epoch 882, Accuracy: 0.8500000238418579\n",
      "Epoch 883, Accuracy: 0.8500000238418579\n",
      "Epoch 884, Accuracy: 0.8500000238418579\n",
      "Epoch 885, Accuracy: 0.8500000238418579\n",
      "Epoch 886, Accuracy: 0.8500000238418579\n",
      "Epoch 887, Accuracy: 0.8500000238418579\n",
      "Epoch 888, Accuracy: 0.8500000238418579\n",
      "Epoch 889, Accuracy: 0.8500000238418579\n",
      "Epoch 890, Accuracy: 0.8500000238418579\n",
      "Epoch 891, Accuracy: 0.8500000238418579\n",
      "Epoch 892, Accuracy: 0.8500000238418579\n",
      "Epoch 893, Accuracy: 0.8500000238418579\n",
      "Epoch 894, Accuracy: 0.8500000238418579\n",
      "Epoch 895, Accuracy: 0.8500000238418579\n",
      "Epoch 896, Accuracy: 0.8500000238418579\n",
      "Epoch 897, Accuracy: 0.8500000238418579\n",
      "Epoch 898, Accuracy: 0.8500000238418579\n",
      "Epoch 899, Accuracy: 0.8500000238418579\n",
      "Epoch 900, Accuracy: 0.8500000238418579\n",
      "Epoch 901, Accuracy: 0.8500000238418579\n",
      "Epoch 902, Accuracy: 0.8500000238418579\n",
      "Epoch 903, Accuracy: 0.8500000238418579\n",
      "Epoch 904, Accuracy: 0.8500000238418579\n",
      "Epoch 905, Accuracy: 0.8500000238418579\n",
      "Epoch 906, Accuracy: 0.8500000238418579\n",
      "Epoch 907, Accuracy: 0.8500000238418579\n",
      "Epoch 908, Accuracy: 0.8500000238418579\n",
      "Epoch 909, Accuracy: 0.8500000238418579\n",
      "Epoch 910, Accuracy: 0.8500000238418579\n",
      "Epoch 911, Accuracy: 0.8500000238418579\n",
      "Epoch 912, Accuracy: 0.8500000238418579\n",
      "Epoch 913, Accuracy: 0.8500000238418579\n",
      "Epoch 914, Accuracy: 0.8500000238418579\n",
      "Epoch 915, Accuracy: 0.8500000238418579\n",
      "Epoch 916, Accuracy: 0.8500000238418579\n",
      "Epoch 917, Accuracy: 0.8500000238418579\n",
      "Epoch 918, Accuracy: 0.8500000238418579\n",
      "Epoch 919, Accuracy: 0.8500000238418579\n",
      "Epoch 920, Accuracy: 0.8500000238418579\n",
      "Epoch 921, Accuracy: 0.8500000238418579\n",
      "Epoch 922, Accuracy: 0.8500000238418579\n",
      "Epoch 923, Accuracy: 0.8500000238418579\n",
      "Epoch 924, Accuracy: 0.8500000238418579\n",
      "Epoch 925, Accuracy: 0.8500000238418579\n",
      "Epoch 926, Accuracy: 0.8500000238418579\n",
      "Epoch 927, Accuracy: 0.8500000238418579\n",
      "Epoch 928, Accuracy: 0.8500000238418579\n",
      "Epoch 929, Accuracy: 0.8500000238418579\n",
      "Epoch 930, Accuracy: 0.8500000238418579\n",
      "Epoch 931, Accuracy: 0.8500000238418579\n",
      "Epoch 932, Accuracy: 0.8500000238418579\n",
      "Epoch 933, Accuracy: 0.8500000238418579\n",
      "Epoch 934, Accuracy: 0.8500000238418579\n",
      "Epoch 935, Accuracy: 0.8500000238418579\n",
      "Epoch 936, Accuracy: 0.8500000238418579\n",
      "Epoch 937, Accuracy: 0.8500000238418579\n",
      "Epoch 938, Accuracy: 0.8500000238418579\n",
      "Epoch 939, Accuracy: 0.8500000238418579\n",
      "Epoch 940, Accuracy: 0.8500000238418579\n",
      "Epoch 941, Accuracy: 0.8500000238418579\n",
      "Epoch 942, Accuracy: 0.8500000238418579\n",
      "Epoch 943, Accuracy: 0.8500000238418579\n",
      "Epoch 944, Accuracy: 0.8500000238418579\n",
      "Epoch 945, Accuracy: 0.8500000238418579\n",
      "Epoch 946, Accuracy: 0.8500000238418579\n",
      "Epoch 947, Accuracy: 0.8500000238418579\n",
      "Epoch 948, Accuracy: 0.8500000238418579\n",
      "Epoch 949, Accuracy: 0.8500000238418579\n",
      "Epoch 950, Accuracy: 0.8500000238418579\n",
      "Epoch 951, Accuracy: 0.8500000238418579\n",
      "Epoch 952, Accuracy: 0.8500000238418579\n",
      "Epoch 953, Accuracy: 0.8500000238418579\n",
      "Epoch 954, Accuracy: 0.8500000238418579\n",
      "Epoch 955, Accuracy: 0.8500000238418579\n",
      "Epoch 956, Accuracy: 0.8500000238418579\n",
      "Epoch 957, Accuracy: 0.8500000238418579\n",
      "Epoch 958, Accuracy: 0.8500000238418579\n",
      "Epoch 959, Accuracy: 0.8500000238418579\n",
      "Epoch 960, Accuracy: 0.8500000238418579\n",
      "Epoch 961, Accuracy: 0.8500000238418579\n",
      "Epoch 962, Accuracy: 0.8500000238418579\n",
      "Epoch 963, Accuracy: 0.8500000238418579\n",
      "Epoch 964, Accuracy: 0.8500000238418579\n",
      "Epoch 965, Accuracy: 0.8500000238418579\n",
      "Epoch 966, Accuracy: 0.8500000238418579\n",
      "Epoch 967, Accuracy: 0.8500000238418579\n",
      "Epoch 968, Accuracy: 0.8500000238418579\n",
      "Epoch 969, Accuracy: 0.8500000238418579\n",
      "Epoch 970, Accuracy: 0.8500000238418579\n",
      "Epoch 971, Accuracy: 0.8500000238418579\n",
      "Epoch 972, Accuracy: 0.8500000238418579\n",
      "Epoch 973, Accuracy: 0.8500000238418579\n",
      "Epoch 974, Accuracy: 0.8500000238418579\n",
      "Epoch 975, Accuracy: 0.8500000238418579\n",
      "Epoch 976, Accuracy: 0.8500000238418579\n",
      "Epoch 977, Accuracy: 0.8500000238418579\n",
      "Epoch 978, Accuracy: 0.8500000238418579\n",
      "Epoch 979, Accuracy: 0.8500000238418579\n",
      "Epoch 980, Accuracy: 0.8500000238418579\n",
      "Epoch 981, Accuracy: 0.8500000238418579\n",
      "Epoch 982, Accuracy: 0.8500000238418579\n",
      "Epoch 983, Accuracy: 0.8500000238418579\n",
      "Epoch 984, Accuracy: 0.8500000238418579\n",
      "Epoch 985, Accuracy: 0.8500000238418579\n",
      "Epoch 986, Accuracy: 0.8500000238418579\n",
      "Epoch 987, Accuracy: 0.8500000238418579\n",
      "Epoch 988, Accuracy: 0.8500000238418579\n",
      "Epoch 989, Accuracy: 0.8500000238418579\n",
      "Epoch 990, Accuracy: 0.8500000238418579\n",
      "Epoch 991, Accuracy: 0.8500000238418579\n",
      "Epoch 992, Accuracy: 0.8500000238418579\n",
      "Epoch 993, Accuracy: 0.8500000238418579\n",
      "Epoch 994, Accuracy: 0.8500000238418579\n",
      "Epoch 995, Accuracy: 0.8500000238418579\n",
      "Epoch 996, Accuracy: 0.8500000238418579\n",
      "Epoch 997, Accuracy: 0.8500000238418579\n",
      "Epoch 998, Accuracy: 0.8500000238418579\n",
      "Epoch 999, Accuracy: 0.8500000238418579\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def torch_fit(X,y,X_train, X_test, y_train, y_test,model, criterion, lr, num_epochs):\n",
    "    optimizer = T.optim.Adam(model.parameters(), lr)\n",
    "    ls = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X_train)\n",
    "        loss_value = criterion(pred, y_train)\n",
    "        train_losses.append(loss_value.item())\n",
    "        #print(f'Epoch {epoch}, loss {loss_value.item():.2f}')\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    \n",
    "        model.eval()\n",
    "        with T.no_grad():\n",
    "\n",
    "            test_preds = model.forward(X_test)\n",
    "            test_loss = criterion(test_preds, y_test)\n",
    "            test_losses.append(test_loss.item())\n",
    "        ls = []\n",
    "        for i in test_preds:\n",
    "            if i > 0.5:\n",
    "                ls.append(1)\n",
    "            else:\n",
    "                ls.append(0)\n",
    "            \n",
    "        ls = T.tensor(ls).view(-1,1)\n",
    "        sc = (ls == y_test).sum()/len(y_test)\n",
    "\n",
    "        print(f'Epoch {epoch}, Accuracy: {sc}')\n",
    "            \n",
    "               \n",
    "    \n",
    "    #acc = tsp / y_test\n",
    "    #print(len(tsp))\n",
    "    #print(acc)\n",
    "    #print(type(y_test))\n",
    "    plt.plot(train_losses)\n",
    "    #plt.show()\n",
    "    plt.plot(test_losses)\n",
    "    plt.show()\n",
    "model = torch_fit(X=X,y=y,X_train=X_train, X_test=X_test,y_train=y_train, y_test=y_test, model=model, criterion=criterion, lr=0.01, num_epochs=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5610, -0.1273],\n",
      "        [ 0.5755,  0.5828],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5846,  0.8434],\n",
      "        [ 1.0184,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5505,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.8597],\n",
      "        [ 0.0000,  0.4997],\n",
      "        [ 0.0169,  0.2732],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.5129,  0.8525],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.8909,  0.9023],\n",
      "        [ 0.0000,  0.4024],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.6170,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.6589,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.6212,  1.0140],\n",
      "        [ 0.0000,  0.9077],\n",
      "        [ 0.0000,  0.6411],\n",
      "        [ 1.3981,  0.7461],\n",
      "        [ 0.0000,  1.3930],\n",
      "        [ 0.3020,  0.0000],\n",
      "        [ 0.3285,  0.5552],\n",
      "        [ 0.6652,  0.1119],\n",
      "        [ 0.0000,  0.5727],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0703],\n",
      "        [ 0.4259,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.5728],\n",
      "        [ 1.3416,  0.0000],\n",
      "        [ 0.7630,  0.0000],\n",
      "        [ 1.0768,  0.6555],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.0905,  1.2782],\n",
      "        [ 0.0000,  0.2401],\n",
      "        [ 0.8443,  1.2333],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.8754],\n",
      "        [ 0.0000,  1.0428],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.7950,  0.6380],\n",
      "        [ 1.1066,  0.0000],\n",
      "        [ 0.8855,  1.1841],\n",
      "        [ 0.0000,  1.3224],\n",
      "        [ 1.2087,  1.7321],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 2.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.9876,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  1.4504],\n",
      "        [ 1.5879,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.1884,  0.0000],\n",
      "        [ 0.0000,  1.1245],\n",
      "        [ 0.0000,  0.7005],\n",
      "        [ 1.5957,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  1.2173],\n",
      "        [ 1.3282,  1.8415],\n",
      "        [ 0.0000,  1.3333],\n",
      "        [ 1.2915,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.2418,  0.0000],\n",
      "        [ 0.0000,  1.1222],\n",
      "        [ 1.1787,  1.4316],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.9282],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.2195,  0.0000],\n",
      "        [ 0.0000,  1.7397],\n",
      "        [ 1.5339,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.3624,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.5229,  1.2028],\n",
      "        [ 1.1797,  0.0000],\n",
      "        [ 1.4629,  1.4903],\n",
      "        [ 1.5406,  1.4028],\n",
      "        [ 0.0000,  1.4356],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.7055,  0.0000],\n",
      "        [ 1.0382,  1.2472]])\n",
      "tensor([[ 0.7805, -0.0637],\n",
      "        [ 0.2877,  0.2914],\n",
      "        [ 0.4071,  0.1788],\n",
      "        [ 0.2923,  0.4217],\n",
      "        [ 0.5092,  0.3526],\n",
      "        [ 0.2779,  0.1080],\n",
      "        [ 0.2753,  0.3322],\n",
      "        [ 0.4400,  0.3124],\n",
      "        [ 0.3356,  0.4298],\n",
      "        [ 0.2345,  0.2499],\n",
      "        [ 0.0084,  0.1366],\n",
      "        [ 0.1242,  0.3359],\n",
      "        [ 0.2564,  0.4262],\n",
      "        [ 0.4591,  0.4043],\n",
      "        [ 0.4455,  0.4512],\n",
      "        [ 0.4222,  0.2012],\n",
      "        [ 0.4956,  0.2145],\n",
      "        [ 0.3085,  0.2431],\n",
      "        [ 0.3971,  0.4444],\n",
      "        [ 0.3295,  0.3922],\n",
      "        [ 0.4074,  0.4027],\n",
      "        [ 0.3106,  0.5070],\n",
      "        [ 0.4964,  0.4538],\n",
      "        [ 0.1007,  0.3205],\n",
      "        [ 0.6991,  0.3731],\n",
      "        [ 0.2977,  0.6965],\n",
      "        [ 0.1510,  0.5734],\n",
      "        [ 0.1643,  0.2776],\n",
      "        [ 0.3326,  0.0560],\n",
      "        [ 0.5374,  0.2864],\n",
      "        [ 0.1950,  0.3688],\n",
      "        [ 0.4028,  0.0351],\n",
      "        [ 0.2130,  0.5517],\n",
      "        [ 0.4845,  0.5699],\n",
      "        [ 0.2548,  0.3460],\n",
      "        [ 0.2173,  0.2864],\n",
      "        [ 0.6708,  0.4654],\n",
      "        [ 0.3815,  0.4622],\n",
      "        [ 0.5384,  0.3277],\n",
      "        [ 0.4849,  0.2607],\n",
      "        [ 0.3710,  0.3881],\n",
      "        [ 0.5453,  0.6391],\n",
      "        [ 0.3215,  0.1201],\n",
      "        [ 0.4222,  0.6167],\n",
      "        [ 0.1019,  0.0604],\n",
      "        [ 0.1525,  0.2168],\n",
      "        [ 0.4556,  0.4377],\n",
      "        [ 0.2849,  0.5214],\n",
      "        [ 0.2763,  0.2126],\n",
      "        [ 0.3975,  0.3190],\n",
      "        [ 0.5533,  1.0000],\n",
      "        [ 0.4427,  0.5921],\n",
      "        [ 0.8518,  0.6612],\n",
      "        [ 0.6044,  0.8661],\n",
      "        [ 0.6824,  0.4830],\n",
      "        [ 1.0000,  0.7681],\n",
      "        [ 0.7299,  0.8107],\n",
      "        [ 0.6738,  0.7797],\n",
      "        [ 0.7876,  0.5818],\n",
      "        [ 0.7144,  0.7668],\n",
      "        [ 0.4938,  0.5423],\n",
      "        [ 0.7897,  0.7423],\n",
      "        [ 0.6791,  0.6092],\n",
      "        [ 0.6642,  0.7252],\n",
      "        [ 0.7940,  0.5679],\n",
      "        [ 0.7076,  0.7602],\n",
      "        [ 0.5942,  0.6186],\n",
      "        [ 0.4936,  0.5622],\n",
      "        [ 0.7771,  0.3503],\n",
      "        [ 0.7979,  0.7692],\n",
      "        [ 0.7088,  0.9676],\n",
      "        [ 0.6918,  0.6087],\n",
      "        [ 0.6641,  0.9208],\n",
      "        [ 0.6597,  0.6667],\n",
      "        [ 0.6457,  0.5684],\n",
      "        [ 0.8964,  0.7085],\n",
      "        [ 0.8548,  0.6317],\n",
      "        [ 0.6209,  0.8042],\n",
      "        [ 0.7906,  0.5611],\n",
      "        [ 0.5893,  0.7158],\n",
      "        [ 0.5685,  0.7406],\n",
      "        [ 0.6591,  0.7155],\n",
      "        [ 0.7094,  0.7404],\n",
      "        [ 0.5915,  0.6293],\n",
      "        [ 0.4583,  0.4641],\n",
      "        [ 0.7998,  0.7485],\n",
      "        [ 0.6097,  0.5476],\n",
      "        [ 0.6813,  0.8698],\n",
      "        [ 0.7669,  0.6474],\n",
      "        [ 0.6905,  0.8306],\n",
      "        [ 0.6812,  0.9654],\n",
      "        [ 0.7323,  0.6424],\n",
      "        [ 0.7614,  0.6014],\n",
      "        [ 0.5899,  0.8695],\n",
      "        [ 0.7315,  0.7452],\n",
      "        [ 0.7703,  0.7014],\n",
      "        [ 0.7316,  0.7178],\n",
      "        [ 0.4456,  0.5799],\n",
      "        [ 0.8528,  0.8599],\n",
      "        [ 0.5191,  0.6236]])\n"
     ]
    }
   ],
   "source": [
    "dropout = nn.Dropout()\n",
    "dropout.train()\n",
    "print(dropout(X))\n",
    "dropout.eval()\n",
    "print(dropout(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0985, 0.8947, 0.7705, 0.9691, 0.9006, 0.0535, 0.1588, 0.4192, 0.1753,\n",
       "        0.8472, 0.1220, 0.2560, 0.0170, 0.2161, 0.9112, 0.9094, 0.8579, 0.8861,\n",
       "        0.9446, 0.3720, 0.7200, 0.9455, 0.6654, 0.9998, 0.7593, 0.8108, 0.3250,\n",
       "        0.7399, 0.5575, 0.3806, 0.2181, 0.2194, 0.1153, 0.8357, 0.8555, 0.4431,\n",
       "        0.2107, 0.8865, 0.8197, 0.5372, 0.2639, 0.9595, 0.7045, 0.1204, 0.9785,\n",
       "        0.8797, 0.3178, 0.7811, 0.2159, 0.4216, 0.9246, 0.5207, 0.1464, 0.3329,\n",
       "        0.3643, 0.4035, 0.5479, 0.9624, 0.5268, 0.1913, 0.5256, 0.7397, 0.7480,\n",
       "        0.0430, 0.4105, 0.1284, 0.2867, 0.6801, 0.1449, 0.6859, 0.9244, 0.5328,\n",
       "        0.1668, 0.3209, 0.6092, 0.1188, 0.7484, 0.0461, 0.0194, 0.0142, 0.3986,\n",
       "        0.8362, 0.0268, 0.9156, 0.3000, 0.6464, 0.5228, 0.0491, 0.9147, 0.7692,\n",
       "        0.9970, 0.7526, 0.1700, 0.9173, 0.5269, 0.7371, 0.0991, 0.3562, 0.0091,\n",
       "        0.3053])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = T.randint(0,2,(100,))\n",
    "preds = T.rand(100)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in preds:\n",
    "    if i > 0.5:\n",
    "        ls.append(1)\n",
    "    else:\n",
    "        ls.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = T.tensor(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "print((ytest == ls).sum()/ len(ytest))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c783155fdf7cc6e25183d446515f6b6ba379df7b28dd698d21634d1b4d5e58fd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
